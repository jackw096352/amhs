{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57fe308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part of code is the Q learning brain, which is a brain of the agent.\n",
    "All decisions are made in here.\n",
    "View more on my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "\"\"\"\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.5, reward_decay=0.9, e_greedy=0.6, tow=3, min_tow=0.01):\n",
    "        self.actions = actions  # a list\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon = e_greedy\n",
    "        self.decay = reward_decay\n",
    "        self.t = tow\n",
    "        self.t_min = min_tow\n",
    "        self.update_times = 0\n",
    "        self.change_threshold = 30\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "        #記得把8跟16的action2加回來\n",
    "        self.action_space = {0:[1],1:[1],2:[2],3:[0,2],4:[2],5:[0,2],6:[2],7:[1],8:[0],9:[3],10:[1,3],11:[3],\n",
    "                            12:[0,2],13:[0,2],14:[2],15:[1],16:[0],17:[3],18:[1,3],19:[3],20:[1,3],21:[3],22:[0],23:[0]}\n",
    "\n",
    "    def epsilon_greedy(self,node_ind,observation):\n",
    "        self.check_state_exist(observation)\n",
    "        # action selection\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # choose best action\n",
    "            state_action = self.q_table.loc[observation, self.action_space[node_ind]]\n",
    "            # some actions may have the same value, randomly choose on in these actions\n",
    "            action = np.random.choice(state_action[state_action == np.min(state_action)].index)\n",
    "        else:\n",
    "            # choose random action\n",
    "            action = np.random.choice(self.action_space[node_ind])\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def boltzmann_softmax(self,node_ind,observation):\n",
    "        self.check_state_exist(observation)\n",
    "        q_value = np.array(self.q_table.loc[observation, self.action_space[node_ind]])\n",
    "        q_avg = abs(np.average(q_value))\n",
    "        if q_avg != 0:\n",
    "            q_value = q_value/q_avg\n",
    "        proba = np.exp(q_value/self.t)/sum(np.exp(q_value/self.t))\n",
    "        #proba = np.exp(-1*q_value/q_avg)/sum(-1*np.exp(q_value/q_avg))\n",
    "        ran = np.random.uniform()\n",
    "        if ran <= proba[0]:\n",
    "            action = self.action_space[node_ind][0]\n",
    "        else:\n",
    "            action = self.action_space[node_ind][1]\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def learn(self, s, a, r, s_, trans_fini,node_ind,now_time):\n",
    "        self.check_state_exist(s_)\n",
    "        q_predict = self.q_table.loc[s, a]\n",
    "        if not trans_fini:\n",
    "            q_target = r + self.gamma * self.q_table.loc[s_, self.action_space[node_ind]].max()  # next state is not terminal\n",
    "        else:\n",
    "            q_target = r  # next state is terminal\n",
    "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)  # update\n",
    "        \n",
    "        self.update_times+=1\n",
    "        if (now_time%self.change_threshold)==0 and self.t>self.t_min:\n",
    "            self.t = self.t*self.decay\n",
    "            print('tow decay')\n",
    "\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            # append new state to q table\n",
    "            self.q_table = self.q_table.append(\n",
    "                pd.Series(\n",
    "                    [0]*len(self.actions),\n",
    "                    index=self.q_table.columns,\n",
    "                    name=state,\n",
    "                )\n",
    "            )\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
